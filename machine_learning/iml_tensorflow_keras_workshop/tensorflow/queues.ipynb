{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing input pipelines in TensorFlow using queues\n",
    "\n",
    "A bottleneck for many machine learning applications is the input pipeline, which means loading inputs (e.g, images) from disk and transport the data to the device (e.g., the GPU). A very important feature of TensorFlow is the capability to design highly efficient solutions for this problem so that the throughput is only limited by the computing power of your device.\n",
    "\n",
    "In TensorFlow, the solution is normally solved by using queues, which are similar to buffers in memory being filled concurrently in multiple threads so that data for the execution of the graph, e.g. for training, is always available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/py2_virtualenv/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy scenario\n",
    "\n",
    "For this example, we are simply writing random numbers to a CSV file, which will be read afterwards in a queue using multiple threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data.csv\", \"w\")\n",
    "for i in range(10000):\n",
    "    f.write(\"{}, {}\\n\".format(np.random.randn(), np.random.randn()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TensorFlow readers\n",
    "\n",
    "Before filling data to a queue, the data has to be read and decoded, which is performed using readers. Multiple readers are implemented in TensorFlow to be used out-of-the-box.\n",
    "\n",
    "The input pipeline usually starts with a special queue, the filename queue. This queue holds only the names of the files, which shall be loaded in the queue. Then, a reader instance is created based on this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"data.csv\"])\n",
    "reader = tf.TextLineReader()\n",
    "_, line = reader.read(filename_queue)\n",
    "value_1, value_2 = tf.decode_csv(line, record_defaults=[[1.0], [1.0]])\n",
    "values = tf.stack([value_1, value_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The queue\n",
    "\n",
    "This example uses a simple first-in-first-out queue. Each queue has always an `enqueue` and a `dequeue` method, which will be used in the following to fill and return values from the queue.\n",
    "\n",
    "In a realistic example, more often a `RandomShuffleQueue` is used, which can be used to return randomized batches of inputs such as used in neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifo_queue = tf.FIFOQueue(capacity=100, dtypes=[tf.float32], shapes=[[2]])\n",
    "enqueue = fifo_queue.enqueue(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the queue in the background\n",
    "\n",
    "So that data is always available in memory, we spawn multiple threads loading data from the defined inputs to the queue concurrently to other executions of the graph. In TensorFlow, you have to add `QueueRunners`, which perform this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 4\n",
    "queue_runner = tf.train.QueueRunner(fifo_queue, [enqueue] * num_threads)\n",
    "tf.train.add_queue_runner(queue_runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning batches from the queue\n",
    "\n",
    "To use data from the queue, simply call the `dequeue` or `dequeue_many` method of the queue. The resulting object is an operation of the graph, which can be fed to any other computation, e.g., it can be used as input node of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "batch = fifo_queue.dequeue_many(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the input pipeline\n",
    "\n",
    "As example, we retrieve some mini-batches of the queue. To do so, we need to create a `Coordinator`, which can be used to organize the `QueueRunners`. Finally, `start_queue_runners` starts the background threads, which now run independently of other `sess.run(...)` exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-batch: 1\n",
      "[[ 0.47143516 -1.1909757 ]\n",
      " [ 1.432707   -0.3126519 ]\n",
      " [-0.72058874  0.8871629 ]\n",
      " [ 0.8595884  -0.6365235 ]\n",
      " [ 0.01569637 -2.2426848 ]]\n",
      "Mini-batch: 2\n",
      "[[ 1.1500357   0.99194604]\n",
      " [ 0.95332414 -2.0212548 ]\n",
      " [ 0.4054534   0.28909194]\n",
      " [-0.33407736  0.00211836]\n",
      " [ 1.3211582  -1.5469055 ]]\n",
      "Mini-batch: 3\n",
      "[[-0.20264633 -0.6559693 ]\n",
      " [ 0.19342138  0.5534389 ]\n",
      " [ 1.3181516  -0.46930528]\n",
      " [ 0.6755541  -1.8170272 ]\n",
      " [-0.18310854  1.0589691 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for i in range(3):\n",
    "        print(\"Mini-batch: {}\".format(i+1))\n",
    "        print(sess.run(batch))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
